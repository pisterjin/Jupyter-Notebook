{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8월 30일"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4ccf4",
   "metadata": {},
   "source": [
    "## AI, ML(머신러닝), NN(뉴런 네트웍:신경망), DNN(deep 뉴런 네트웍:신경망), Deep Learning\n",
    "- 머신러닝(기계학습)은 AI를 구현하기 위한 하나의 방법\n",
    "- 머신러닝, 신경망, 딥러닝을 통해 AI 구현\n",
    "- 뉴런 네트워크(Neural Networks)는 머신러닝 중 하나의 방법인 것\n",
    "- 요즘의 인공지능은 빅데이터를 통해서 접근하는 것이나 빅데이터가 아니어도 AI에 접근하는 방법은 있다는 것을 그래프에서 알 수 있다\n",
    "- 딥러닝은 머신러닝의 일종이며 신경망을 이용하고 그 중에서도 DNN(심층 인공신경망)을 이용해 기계학습을 시키는 것\n",
    "- 생체 세포의 신경망[신호 체계]의 작용을 본따서 소프트웨어적으로 신경망을 모방해서 만든 게 인공신경망이라고 함\n",
    "- Artificial Neural Networks => 인공신경망은 앞에 Artificial이 붙음.(생체 신경망은 Bio Neural Networks)\n",
    "- 사이킷런에는 라이브러리가 포함돼 있지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f83711",
   "metadata": {},
   "source": [
    "<img src='https://cwisky.github.io/public/images/bigdata_ai.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a4c3d",
   "metadata": {},
   "source": [
    "# 신경망과 딥러닝을 위한 라이브러리:\n",
    "\n",
    "- TensorFlow: Google Brain 팀에서 개발한 오픈소스 라이브러리로, 데이터 플로우 그래프를 사용하여 수치 계산을 수행. \n",
    "<br>각 노드는 수학적 연산을 나타내고, 그래프의 변은 다차원 데이터 배열(즉, 텐서)을 나타냄.\n",
    "- Keras: TensorFlow, Theano 및 CNTK와 같은 여러 백엔드 엔진 위에서 실행될 수 있는 고수준 신경망 API. \n",
    "<br>간결하고 쉬운 API로 인해 입문자들에게 인기.\n",
    "- PyTorch: Facebook의 AI Research lab (FAIR)에서 개발한 오픈소스 라이브러리. \n",
    "<br>PyTorch는 GPU 가속 지원과 함께 동적 컴퓨팅 그래프를 제공하여 국소적인 최적화를 가능하게 함.\n",
    "- Theano: Montreal 대학교에서 개발한 Python 라이브러리로, GPU 지원과 함께 심볼릭 연산을 가능하게 함.\n",
    "- Caffe (Convolutional Architecture for Fast Feature Embedding): 이미지 분류와 컨볼루션 네트워크 관련 작업에 \n",
    "<br>적합하도록 설계된 프레임워크.\n",
    "- MXNet: Amazon Web Services (AWS)가 후원하는 딥러닝 프레임워크로서, \n",
    "<br>다양한 언어 인터페이스 지원(Python, R, Scala 등)과 유연성 및 효율성 면에서 장점을 가짐.\n",
    "- 기타 등등\n",
    "- 각 라이브러리는 자신만의 장단점과 특징들을 가지고 있으므로 원하는 작업에 가장 적합한 것을 선택."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ded31f",
   "metadata": {},
   "source": [
    "## 생체 신경세포\n",
    "<img src='https://cwisky.github.io/public/images/neuron.jfif'>\n",
    "- 의미있는 자극만 신경 세포에 전달<br>\n",
    "- 인공 신경세포도 의미 없는 가중치는 낮은 수로 전달(가중치를 부여할 수도 부여하지 않을 수도 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 신경세포(뉴런)의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589e340",
   "metadata": {},
   "source": [
    "## 단층 인공 신경망의 구조\n",
    "- 최초의 인공 신경망은 한 개의 레이어였음\n",
    "- 한층으로 구성되어 있어 풀 수 없는 문제가 많았음\n",
    "- 값을 아무리 내보내도 선형 결과밖에 나오지 않음[즉 직선으로 분류, 예측이 가능한 결과만 나옴]\n",
    "\n",
    "<img src='https://cwisky.github.io/public/images/deep01.jfif'>\n",
    "- threshold가 일정 임계치를 넘으면 활성함수(활성함수가 활성화시킬지 여부 결정)에 전달하고, 임계치를 못 넘으면 버림<br>\n",
    "- cf) 입력이 있고 출력이 있는 것을 다 함수라고 함<br>\n",
    "- 활성함수가 다른 신경망으로 내보낼 것인지 안 보낼 것인지를 X1*W1+X2*W2+...+Xn*Wn+b의 결과값을 전달 받아 결정<br>\n",
    "- 가중치(=weight): 처음에는 가중치가 무작위로 설정됨<br>\n",
    "- 가중치가 입력값(입력된 데이터 x)의 중요도(영향력)를 결정<br>\n",
    "- X1*W1+X2*W2+...+Xn*Wn+b  => y= aX+b가 됨 [y라는 값을 만들어냄]<br>\n",
    "- 계수 'W'가 커지면 기울기가 커져서 직선이 더 일어서는 모양이 됨(각도가 커짐)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b333e1",
   "metadata": {},
   "source": [
    "### 활성화 함수와 임계값 차이 비교\n",
    "\n",
    "- 활성화 함수와 임계값의 관계를 이해하는 데에 있어서는, 각각의 역할과 실행 순서를 명확히 이해하는 것이 중요.\n",
    "\n",
    "- 임계값(Threshold): 신경망의 각 노드에서, 입력 값과 해당 입력의 가중치를 곱한 값들을 모두 합한 결과, \n",
    "    <br>즉 가중합(weighted sum)이 어떤 특정 임계값보다 크거나 작은지 판단하는 기준점.\n",
    "- 활성화 함수(Activation Function): 활성화 함수는 그 다음 단계로, 앞서 계산된 가중합에 적용되어 최종적인 노드의 출력 값을 결정.\n",
    "    \n",
    "- 즉, 처음에 각 입력에 대한 가중합이 계산되고 이 값이 임계값과 비교됨. \n",
    "- 그런 다음 활성화 함수가 이 값을 받아서 최종 출력 값을 생성.\n",
    "- 하지만 현재 대부분의 딥러닝 모델에서는 활성화함수가 연속적인 값을 반환하며 (예: 시그모이드 함수), \n",
    "- 이 경우 '임계값' 개념은 명시적으로 사용되지 않음. 임계값 대신 활성화함수 자체가 입력된 값에 따라 출력을 결정하기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98244840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형(직선) 결과(예측 가능)만 나오고 단층이라 예측이 어려운 것들은 풀기 어려웠음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72990d35",
   "metadata": {},
   "source": [
    "## 심층 인공신경망(Deep Neural Network)\n",
    "<img src='https://cwisky.github.io/public/images/deep_learning.jpg'>\n",
    "- 레이어 단층으로는 선형 결과만 나오나 심층 인공신경망은\n",
    "   <br>비선형 결과 가능(직선으로 안 되는 것을 곡선으로 해결 => 곡선 분류 가능해짐)<br>\n",
    "- 한 레이어[첫번째 신경망=> Input Layer]의 결과값이 또다른 신경망 하나에 입력되어 연결되는 작업이 반복[다층 구조]<br>\n",
    "- 레이어(입력층), 레이어(은닉층), 레이어(출력층) 구조로 되어 있음 => 은닉층은 사람이 결정<br>\n",
    "- 레이어 안에 여러 개의 뉴런 생성(뉴런의 수는 사람이 결정 가능)<br>\n",
    "- 뉴런에 활성 함수 => 레이어에 각 가중치 전달(하나의 뉴런이 가지고 있는 연결선[데이터]에 가중치가 들어있음)<br>\n",
    "- 출력층 레이어에 각 분류 결과가 수치로 저장됨<br>\n",
    "- 전결합층-(Fully Connected Layer)을 'FC'라고 줄여서 표현- 연결<br>\n",
    "- 딥러닝 모델, 특히 컨볼루션 신경망(Convolutional Neural Network, CNN)에서 전결합층은 주로 네트워크의 마지막 부분에 위치하여\n",
    "   <br>최종적인 분류를 수행하는 역할을 함. 이때 각 노드는 클래스별 확률을 나타내며, 이 확률들은 모두 합치면 1이 됨.<br>\n",
    "- 은닉층을 몇 단계로 할 것인지 개수는 사람이 결정할 수 있으며 이론상 단계가 많아질수록 비선형성은 증가하기 때문에 더 복잡한 문제를 풀 수 있게 됨<br>\n",
    "- 분류를 하는 경우라면 최종 아웃풋의 출력 레이어의 뉴런의 수를 몇 개로 분류하게 만들지 결정하여 원하는 출력 개수가 나오게 맞춰주어야 함\n",
    "  <br>=> 예를 들어 사진을 주고 개인지 고양이인지 분류하라고 하면 개일 확률 70%, 고양이일 확률 30% 이렇게 숫자 2개(70%, 30%)는 나와야 함<br>\n",
    "- 회귀는 숫자 맞추기이므로 아웃풋의 출력 레이어 뉴런의 수를 한 개로 줘야 함\n",
    "- 출력 레이어의 뉴런의 수는 사람이 정해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7574458",
   "metadata": {},
   "source": [
    "### 용어 정리\n",
    "\n",
    "- 인공 신경망\"은 전체 구조를 나타내며, \"신경망 레이어\"는 네트워크 내의 개별 계층을 나타내는 용어\n",
    "\n",
    "- \"신경\"이 모여 \"신경망\"을 이루고, 이 신경망 내에서 여러 신경들이 모인 그룹을 \"레이어\" 또는 \"층\"이라고 부름.\n",
    "\n",
    "- 신경(Neuron): 인공 신경망의 기본 구성 요소로, 생물학적 뇌의 뉴런을 모방한 것 \n",
    "\n",
    "- 각 신경(또는 노드, 유닛)는 하나 이상의 입력을 받아서 처리하고, 그 결과를 출력으로 내보냄. \n",
    "  <br>=> 이 처리 과정은 주로 입력에 가중치를 곱하고 편향을 더하는 선형 변환과 비선형 활성화 함수를 거치게 됨\n",
    "\n",
    "- 신경망(Neural Network): 여러 개의 신경(노드)이 서로 연결되어 복잡한 패턴을 학습하고 예측할 수 있도록 구성된 시스템. \n",
    "  <br>=> 이러한 신경들은 일반적으로 계층적인 구조인 층(Layer) 형태로 배열됨.\n",
    "\n",
    "- 레이어(Layer): 인공 신경망에서 특정 계층에 속하는 모든 노드들을 의미. \n",
    "  <br>=> 각 층은 보통 한 종류의 연산(예: convolutional operation, pooling operation, fully connected operation 등)만 수행.\n",
    "\n",
    "- 입력 층(Input Layer): 네트워크가 받아들이는 원시 데이터(예: 이미지 픽셀값, 오디오 샘플 데이터 등)가 있는 곳.\n",
    "\n",
    "- 은닉 층(Hidden Layer): 입력 층과 출력 층 사이에 위치해 있으며, 여러 개가 있을 수 있음. \n",
    "  <br>=> 이곳에서 대부분의 학습 및 변환 작업이 일어남.\n",
    "\n",
    "- 출력 층(Output Layer): 네트워크가 최종 예측값 or 분류 결과를 제공하는 곳.\n",
    "\n",
    "- 딥러닝 모델에서 '딥(deep)'은 이런 '레이어' or '계층'이 많다는 것을 의미 \n",
    "  <br>=> 즉 복잡한 문제를 해결하기 위해 많은 계산 단계를 거친다는 것."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32e403",
   "metadata": {},
   "source": [
    "## 순방향 전파[순전파]\n",
    "<img src='https://cwisky.github.io/public/images/deep02.jpg'>\n",
    "\n",
    "<br>\n",
    "- 숫자가 한 개 나왔으므로 숫자 맞추기인 회귀를 위한 시스템임<br>\n",
    "- Input Layer는 가중치를 무작위로 받아들이므로 가중치를 변환하지 않음<br>\n",
    "- Hidden 층에 있는 계단 모형은 활성함수를 의미하며 0 또는 1 등으로 변환해 내보낼지를 결정(모든 활성함수가 0 또는 1을 내보내는 것은 아님)<br>\n",
    "- 프로그램 코드로 각 레이어를 만들고 필요시 뉴런의 수도 정해야 함<br>\n",
    "- Dence라는 클래스 안에 3을 주면 뉴런이 3이 생기게 됨<br>\n",
    "- 다층 구조를 주게 되면 하나의 레이어에 각 뉴런이 여러 개의 가중치(파라미터)를 가지고 하나의 값을 전달하고 활성함수에 의해 값이 변환되기 때문에 엄청난 변화가 생기게 됨<br>\n",
    "- 레이어를 다층으로 만들고 각 뉴런들의 가중치를 전결합층으로 전달하는 이유는 복잡한 변수를 찾기 위함임<br>\n",
    "- 네 개의 뉴런이 어떻게 만드냐에 따라 수십만개의 가중치를 가질 수도 있음<br>\n",
    "- 입력값에 대해 사람이 인지하지 못한 특징적인 변수를 내부에서 찾아 가중치를 적용해 학습함<br>\n",
    "- 값에 변화를 주고 가중치를 붙여 비선형 효과를 내기 위해 복잡한 구조로 되어 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e740f",
   "metadata": {},
   "source": [
    "### 용어 정리\n",
    "\n",
    "\"전결합층(Fully Connected Layer)\"과 \"밀집층(Dense Layer)\"은 동일한 개념을 가리키는 용어.\n",
    "\n",
    "\"전결합층\"이라는 표현은 이 층의 모든 뉴런이 이전 층의 모든 뉴런과 연결되어 있다는 사실을 강조하기 때문에 \n",
    "<br>'Fully Connected'의 약자인 'FC'라고도 부르는 것이고,\n",
    "<br>반면에 \"밀집층(Dense Layer)\"이라는 용어는 Keras와 같은 딥러닝 프레임워크에서 주로 사용하는 표현으로 \n",
    "<br>'Dense'란 단어가 '밀집된, 조밀한'이란 의미를 가지므로, \n",
    "<br>이 역시 모든 뉴런들이 서로 밀접하게 연결되어 있다는 사실을 시사함.\n",
    "<br>따라서, 전결합층(Fully Connected Layer) 혹은 밀집층(Dense Layer) 모두 같은 의미로 사용되며, \n",
    "<br>어떤 용어를 사용할지는 주로 사용하는 프레임워크나 개인의 선호에 따라 다름."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b921fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴런에서 나오는 것은 하나의 숫자임\n",
    "# 출력층이 하나면 회귀(숫자 맞추기)\n",
    "# 분류면 출력층이 두 개 이상(입력에서 출력으로) \n",
    "# 가중치는 초반엔 무작위로 생성되나 학습하면서 결정됨\n",
    "# 사람은 어떤 변수가 내부에서 생성되는지 알 수 없는 단점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb1c3c2",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network \n",
    "<img src='https://cwisky.github.io/public/images/feed_forward.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6ea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음에 나오는 값 y는 반드시 오류가 나게 돼 있음\n",
    "# 지도 학습에서 실제값과 예측값 사이에 오차를 계산하는 함수를 손실 함수라고 함\n",
    "# => 실제 오류시 loss 함수 넣으라고 출력값에 나옴(손실 함수에 여러 가지가 있으므로 골라 써야 함)\n",
    "# 오차가 계산되는 것까지가 순전파임\n",
    "# 활성 함수도 여러 개가 있으므로 골라 써야 함(실제 오류시 Activation 쓰라고 나옴)\n",
    "# 입력부터 오차 계산까지의 과정을 순방향 전파라고 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33736158",
   "metadata": {},
   "source": [
    "```\n",
    "지도 학습에서 신경망이 처음 학습을 시작할 때, 실제값과 예측값 사이에 오차가 발생하는 이유는 \n",
    "가중치와 편향이 초기화 단계에서 무작위 값으로 설정되기 때문. \n",
    "이 초기화 과정은 일반적으로 균일 분포(uniform distribution)나 정규 분포(normal distribution) 등을 따르는 난수를 사용하여 진행됨.\n",
    "\n",
    "따라서, 모델이 아직 어떤 데이터도 보지 않았거나 학습을 시작한 초기 단계에서는 예측값이 실제값과 상당히 다를 확률이 높음. \n",
    "이렇게 발생하는 오차를 계산하고 최소화하는 것이 바로 손실 함수(loss function)의 역할임.\n",
    "\n",
    "손실 함수의 값(즉, 실제값과 예측값 사이의 오차)을 최소화하도록 \n",
    "모델의 가중치와 편향을 조정하는 과정을 '학습' 또는 '훈련'이라고 함. \n",
    "이런 방식으로 모델은 데이터로부터 패턴을 배우며 점점 더 정확한 예측을 수행하게 됨.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7f9d2",
   "metadata": {},
   "source": [
    "```\n",
    "비지도 학습에서는 일반적으로 실제값(정답 레이블)이 주어지지 않기 때문에, \n",
    "지도 학습에서처럼 예측값과 실제값 사이의 오차를 계산하는 손실 함수를 사용하는 것은 어려움. \n",
    "하지만 이는 손실 함수를 사용하지 않는다는 의미가 아님.\n",
    "\n",
    "비지도 학습에서도 목표에 따라 다양한 손실 함수가 사용됨. \n",
    "예를 들어 클러스터링 알고리즘인 K-평균(K-means)에서는 \n",
    "각 데이터 포인트와 그것이 할당된 클러스터 중심 사이의 거리(오차)를 최소화하는 방식으로 작동. \n",
    "이 경우, 손실 함수로서 '거리'가 사용되며, 이 값을 최소화하는 것이 목표임.\n",
    "\n",
    "또 다른 예로 생성적 적대 신경망(GANs) 같은 경우에는 \n",
    "생성자(generator)와 판별자(discriminator) 간의 게임 이론적 접근을 통해 손실 함수를 정의함. \n",
    "여기서 생성자는 판별자가 구분하지 못하게 가짜 데이터를 만들어내려고 하며, \n",
    "판별자는 진짜와 가짜 데이터를 잘 구분하려고 함. 이 과정에서 발생하는 '경쟁'을 통해 모델은 점진적으로 개선됨.\n",
    "\n",
    "따라서 비지도학습에서도 특정 목표 달성을 위해 적절한 손실함수가 정의되고 사용됨.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947581d",
   "metadata": {},
   "source": [
    "## 오차 역전파(Back Propagation)  \n",
    "- propagation [prɑ̀pəɡéiʃən] (동식물의) 번식, 증식, (소리 등의) 전파, 전달; (특질의) 유전\n",
    "<img src='https://cwisky.github.io/public/images/BackPropaga.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에러 발생시 역으로 가면서 가중치를 수정해서 결과 재생성\n",
    "# 가중치 가감 결정은 경사 하강법을 이용(오류량과 가중치와의 관계 이용)\n",
    "# 경사하강 이용시 에러와 가중치 가이의 차이를 보면 음수가 있으면 덧셈시 에러량이 변동되므로 제곱을 해서 합해 루트 씌움\n",
    "# 경사 하강을 통한 가중치 결정은 미분을 해서 기울기가 0의 자리가 나오면 오류가 최소가 되니 그때 학습을 종료(가중치 최종 결정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7a5ef",
   "metadata": {},
   "source": [
    "## 가중치(계수, 기울기) 재조정\n",
    "<img src='https://cwisky.github.io/public/images/gradient_adjust.gif'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight: 경사(가중치) 재조정[가중치 = 계수 = 기울기 => 모두 동의어]\n",
    "# 가중치 결정은 미분을 해서 정하나 계수를 조금씩 변경해가며 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823af23",
   "metadata": {},
   "source": [
    "## GRADIENT DESCENT & BACK PROPAGATION\n",
    "<img src='https://cwisky.github.io/public/images/weight_update.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fa51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성함수가 선형을 비선형으로 바꿔줌, 출력값에도 영향"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca605b4e",
   "metadata": {},
   "source": [
    "## 경사하강법(Gradient Descent)\n",
    "<img src='https://cwisky.github.io/public/images/gradient_descent.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dabc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기울기(경사)가 급하면 경사가 제로인 곳에서 멀다 보니 가중치를 크게(많이) 바꿔 오류가 최소화되게끔 빠르게 학습시켜야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성함수 뭐 써야할 지, 손실함수(로스함수) 뭘 써야할 지, \n",
    "# 옵티마이저(가중치와 오류 사이에 경사가 완만해지면 가중치를 알아서 작게 조절해주는 알고리즘임)를 뭘 써야할 지는 \n",
    "# 우리가 지정하는데 거의 뭘 써야 하는지는 정해져 있음(총 3개인데 하나는 못 들음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b89c1d",
   "metadata": {},
   "source": [
    "# 활성함수(Activation Function)\n",
    "- 신경망에 비선형성 처리 기능 부여\n",
    "- 선형적인 방법으로 해결하지 못했던 XOR 문제를 비선형적인 방법으로 해결했다\n",
    "- 입력된 변수들을 조합하여 더 복잡한 변수를 생성하여 가중치 학습\n",
    "- 사람이 인지하지 못했던 새로운 feature를 발견하고 학습에 활용\n",
    "- 가중치 학습시 오차가 적게 발생하도록 유도함 \n",
    "- 신경망을 통해 산출되는 값의 결정경계(Decision Boundary)를 형성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597061d0",
   "metadata": {},
   "source": [
    "## 선형(Linearity)\n",
    "- f(x+y) = f(x)+f(y) 또는 f(ax) = af(x) => 함수의 파라미터로 전달할 때 나눠서 계산한 것과 원래의 계산 값이 같아야 하는 게 선형의 기본 조건임[동차성]\n",
    "- 내부의 조작이 별로 없거나 동일한 비율 등의 뻔한 조작을 해야 함\n",
    "- 입력값에 대한 출력값이 직선으로 나타나기 때문에 선형 함수라고 함(가산성과 동차성만 만족하면 선형 함수가 될 수 있음)\n",
    "- 아래의 2가지 성질을 만족하는 함수는 선형성이다\n",
    "- Additivity(가산성): f(x + y) = f(x) + f(y) \n",
    "- Homogeneity(동차성):  f(ax) = af(x)\n",
    "- 선형으로 나타나는 값은 예측이 쉽고 단순한 데이터셋이다\n",
    "- 선형함수가 리턴한 값은 평면에 직선으로 표시된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8abf12",
   "metadata": {},
   "source": [
    "## 비선형(Non-linearity)\n",
    "- 자연은 주로 비선형 상태로 되어 있음\n",
    "- 가산성, 동차성을 만족하지 않는 함수는 비선형 함수이다\n",
    "- 비선형 함수가 리턴한 값은 평면에 곡선으로 표시된다\n",
    "- 많은 실세계의 데이터는 비선형으로 나타난다(기하급수적 증가, 로그함수적 감소 등)\n",
    "- 지수함수, 로그함수, 삼각함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb448130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vp": {
   "vp_config_version": "1.0.0",
   "vp_menu_width": 273,
   "vp_note_display": false,
   "vp_note_width": 0,
   "vp_position": {
    "width": 278
   },
   "vp_section_display": false,
   "vp_signature": "VisualPython"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
